{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TexGen File Parsing and Processing\n",
    "This section goes through all the preliminary steps necessary to proccess the export file from TexGen. You will need to edit the file names and dimensions in the 3rd code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linprog\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is some stuff related to the scaling from TexGen to Macaw. Mostly just scratch work, but it does include NonDimConv which scales things later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YarnHeight = 0.1\n",
    "YarnWidth = 0.8\n",
    "\n",
    "TowAreaInMicronSquared = 112257.84\n",
    "\n",
    "ratio = YarnWidth/YarnHeight\n",
    "\n",
    "TexGenToMicron = math.sqrt(TowAreaInMicronSquared/(math.pi *ratio))/(YarnHeight/2)\n",
    "print(TexGenToMicron)\n",
    "# 4644 * 120 = 557280\n",
    "# NonDimConv1 = TexGenToMicron/557280\n",
    "# print(1/NonDimConv1)\n",
    "\n",
    "# NonDimConv = 4644 * TexGenToMicron\n",
    "NonDimConv = 557280\n",
    "print(NonDimConv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a box the same size as our TexGen file. We also define the number of points that we want in each direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputFileName = 'ExampleFiber.inp'\n",
    "OutputFileNameBase = 'ExampleFiber_'\n",
    "\n",
    "\n",
    "x_max = 2.5 \n",
    "x_min = -0.5\n",
    "y_max = 0.5\n",
    "y_min = -0.5\n",
    "z_max = 0.21 \n",
    "z_min = -0.01\n",
    "\n",
    "x_dim = round(512 * (x_max - x_min))\n",
    "y_dim = round(512 * (y_max - y_min))\n",
    "z_dim = round(512 * (z_max - z_min))\n",
    "\n",
    "x_step = (x_max - x_min)/x_dim\n",
    "y_step = (y_max - y_min)/y_dim\n",
    "if z_dim != 0: \n",
    "    z_step = (z_max - z_min)/z_dim\n",
    "\n",
    "print(f\"x_dim: {x_dim}, y_dim: {y_dim}, z_dim: {z_dim}\")\n",
    "print(f\"x_step: {x_step}, y_step: {y_step}, z_step: {z_step}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the box that we just defined, we can create a list of points so they are evenly spaced throughout the box. This is the basis of how an EBSD input file is meant to look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start_value = x_min + x_step/2\n",
    "y_start_value = y_min + y_step/2\n",
    "z_start_value = z_min + z_step/2\n",
    "print(f\"x_start_value: {x_start_value}, y_start_value: {y_start_value}, z_start_value: {z_start_value}\")\n",
    "\n",
    "allpointslist = []\n",
    "\n",
    "if z_dim == 0:\n",
    "    print(\"2D file\")\n",
    "    y_value = y_start_value\n",
    "    for _ in range(y_dim):\n",
    "        x_value = x_start_value\n",
    "        for _ in range(x_dim):\n",
    "            allpointslist.append(pd.to_numeric(\"{:.5f}\".format(x_value)))\n",
    "            allpointslist.append(pd.to_numeric(\"{:.5f}\".format(y_value)))\n",
    "            allpointslist.append(0)\n",
    "            x_value += x_step\n",
    "        y_value += y_step\n",
    "else:\n",
    "    print(\"3D file\")\n",
    "    z_value = z_start_value\n",
    "    for _ in range(z_dim):\n",
    "        y_value = y_start_value\n",
    "        for _ in range(y_dim):\n",
    "            x_value = x_start_value\n",
    "            for _ in range(x_dim):\n",
    "                allpointslist.append(pd.to_numeric(\"{:.5f}\".format(x_value)))\n",
    "                allpointslist.append(pd.to_numeric(\"{:.5f}\".format(y_value)))\n",
    "                allpointslist.append(pd.to_numeric(\"{:.5f}\".format(z_value)))\n",
    "                x_value += x_step\n",
    "            y_value += y_step\n",
    "        z_value += z_step\n",
    "\n",
    "\n",
    "        \n",
    "x = int(len(allpointslist)/3)\n",
    "# print(x)\n",
    "\n",
    "allpointsarray = np.array(allpointslist)\n",
    "allpointsarray = allpointsarray.reshape(x,3)\n",
    "allpointsdf = pd.DataFrame(allpointsarray)\n",
    "allpointsdf.to_csv(\"AllPoints3D.csv\", header=False, index=False, float_format='%.5f')\n",
    "# print(allpointsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section goes through the TexGen file that we want to recreate. It creates a csv file for each of the important bits of information that we will want to reference later. It wouldn't be hard to make it so we just use dataframes instead of csv files, but I find that they're potentially convenient for troubleshooting if necessary so I never felt the need to change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarns = 1\n",
    "\n",
    "with open(InputFileName,\"r\") as infile:\n",
    "    with open(\"AllNodes.csv\",'w') as AllNodes:\n",
    "        for line in infile:\n",
    "            if line.startswith(\"*Node\"):\n",
    "                for line in infile:\n",
    "                    with open(\"AllElements.csv\",'w') as AllElements:\n",
    "                        if line.startswith(\"*Element\"):\n",
    "                            for line in infile:\n",
    "                                if line.startswith(\"*************\"):\n",
    "                                    with open(\"AllElementSets.csv\",'w') as AllElementSets:\n",
    "                                        for line in infile:\n",
    "                                            if line.startswith(\"*ElSet, ElSet=Yarn0\"):\n",
    "                                                for line in infile:\n",
    "                                                    if line.startswith(\"*ElSet\"):\n",
    "                                                        yarns += 1\n",
    "                                                    if line.startswith(\"****\"):\n",
    "                                                        break\n",
    "                                                    else:\n",
    "                                                        AllElementSets.write(line)\n",
    "                                            # else:\n",
    "                                            #     print(line)\n",
    "                                                    \n",
    "                                else:\n",
    "                                    AllElements.write(line)\n",
    "                        else:\n",
    "                            AllNodes.write(line)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read these two csvs into dataframes. Elements are our shapes that we will treat as hulls that form the fibers. Nodes are just any xyz coordinate that the TexGen file defines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllElements = pd.read_csv(\"AllElements.csv\", header=None)\n",
    "AllNodes = pd.read_csv(\"AllNodes.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary that holds all the different yarns based on the number defined in the TexGen file. The print line shows the count for number of yarns (starting at 0). This also attributes each element to its respective yarn number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "\n",
    "with open(\"AllElementSets.csv\", \"r\") as AllElementSets:\n",
    "    for yarn in range(yarns):\n",
    "        print(yarn)\n",
    "        d[\"Yarn{0}\".format(yarn)] = []\n",
    "        for rec in csv.reader(AllElementSets, delimiter=','):\n",
    "            if '*ElSet' in rec:\n",
    "                break\n",
    "            else:\n",
    "                newrec =  list(map(int,rec))\n",
    "                for item in newrec:\n",
    "                    d[\"Yarn{0}\".format(yarn)].append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a copy of the points in our box so that we have them in a testable format. Then we add our \"inHull\" column to the dataframe that defines all the points in our box. This column will essentially hold our grain/fiber number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = allpointsdf[[0,1,2]].to_numpy()\n",
    "allpointsdf.insert(3, \"inHull\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the in_hull function which we use to check if points are inside of a \"hull\". The TexGen file saves each fiber as a combination of multiple different elements based on a number of nodes which are defined with a counter identifier and xyz coordinates. We count each element as a hull and then check whether a given point is in that hull, then we can assign it to a fiber if it's in a hull that is part of a specific fiber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_hull(p, hull):\n",
    "    \"\"\"\n",
    "    Test if points in `p` are in `hull`\n",
    "\n",
    "    `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "    `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "    coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "    will be computed\n",
    "    \"\"\"\n",
    "    if not isinstance(hull,Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "\n",
    "    return hull.find_simplex(p)>=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the magic happens and is typically the longest running section, especially for larger 3D files. We are going through each point defined in our box and checking against each element to determine if it is inside any of them. Since we attributed each element to a specific yarn, we then can define our \"inHull\" column as the respective fiber number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hulldict = {}\n",
    "\n",
    "for yarn in range(yarns):\n",
    "    listofpoints = []\n",
    "    for element in d[\"Yarn{0}\".format(yarn)]:\n",
    "        eles = AllElements.loc[element-1,1:]\n",
    "        for each in eles:\n",
    "            for i in AllNodes.loc[each-1,1:]:\n",
    "                listofpoints.append(i)\n",
    "    length = int(len(listofpoints)/3)\n",
    "    arrayofpoints = np.array(listofpoints)\n",
    "    \n",
    "    \n",
    "    newlength = int(length/10)\n",
    "\n",
    "\n",
    "    arrayofpoints = arrayofpoints.reshape(length,3)\n",
    "    newarrayofpoints = arrayofpoints.reshape(newlength,10,3)\n",
    "    \n",
    "\n",
    "    for testplot in newarrayofpoints:\n",
    "        allpointsdf['inHull'] = allpointsdf['inHull'].mask(allpointsdf['inHull']==0,in_hull(tested,testplot).astype(int)*(yarn+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test to make sure our code worked. This just shows a graphical representation of what our box looks like now that we have checked each point in the box against the elements in our TexGen file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "x = allpointsdf.iloc[:,0]\n",
    "y = allpointsdf.iloc[:,1]\n",
    "z = allpointsdf.iloc[:,2]\n",
    "\n",
    "ax.scatter(x, y, z, c=allpointsdf.loc[:,\"inHull\"], alpha=0.01, cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic 2D File Generation\n",
    "This takes a slice from the 3D model and uses it for the 2D file example. It slices through the middle of the Y axis and then flips it so the Z axis is treated as the Y axis for Macaw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again create our new dataframe to work with. Then we take a 2D slice of our box. This example pulls an XZ slice from the middle of Y axis of our box. This was just chosen because it's the most interesting for this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDebsddf = allpointsdf.copy(deep=True)\n",
    "twoDebsddf = twoDebsddf[twoDebsddf[1] == pd.to_numeric(\"{:.5f}\".format(y_start_value+(y_dim/2-1)*y_step))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick graph to show our 2D slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "x = twoDebsddf.iloc[:,0]\n",
    "y = twoDebsddf.iloc[:,1]\n",
    "z = twoDebsddf.iloc[:,2]\n",
    "\n",
    "ax.scatter(x, y, z, c=twoDebsddf.loc[:,\"inHull\"], alpha=0.1, cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDebsddf[0] = twoDebsddf[0] * NonDimConv\n",
    "twoDebsddf[1] = twoDebsddf[1] * NonDimConv\n",
    "twoDebsddf[2] = twoDebsddf[2] * NonDimConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick graph to show how we actually want this to look in Macaw since it prefers XY systems instead of XZ systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "x = twoDebsddf.iloc[:,0]\n",
    "y = twoDebsddf.iloc[:,2]\n",
    "z = twoDebsddf.iloc[:,1]\n",
    "\n",
    "ax.scatter(x, y, z, c=twoDebsddf.loc[:,\"inHull\"], alpha=0.1, cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusts our dataframe to match the graph from above. Then we add our phase values and extra columns required for the EBSD Reader file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDebsddf= twoDebsddf.drop(columns=[1])\n",
    "twoDebsddf = twoDebsddf.rename(columns={0: \"x\", 2: \"y\"})\n",
    "twoDebsddf['phase'] = twoDebsddf['inHull'].mask(twoDebsddf['inHull'] >0, 2)\n",
    "twoDebsddf['phase'] = twoDebsddf['phase'].mask(twoDebsddf['phase'] <1, 1)\n",
    "twoDebsddf.insert(2, \"z\", 0)\n",
    "twoDebsddf.insert(0, \"phi1\", 0)\n",
    "twoDebsddf.insert(1, \"phi2\", 0)\n",
    "twoDebsddf.insert(2, \"phi3\", 0)\n",
    "twoDebsddf.insert(8, \"symmetry\", 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates our 2D EBSD file that we can import into Macaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OutputFileNameBase+\"2D_ebsd.txt\", \"w\") as file:\n",
    "    file.write(f'# X_STEP: {x_step* NonDimConv}\\n')\n",
    "    file.write(f'# Y_STEP: {z_step* NonDimConv}\\n')\n",
    "    file.write(f'# Z_STEP: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MIN: {x_min* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MIN: {z_min* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MIN: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MAX: {x_max* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MAX: {z_max* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MAX: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_DIM: {x_dim}\\n')\n",
    "    file.write(f'# Y_DIM: {z_dim}\\n')\n",
    "    file.write(f'# Z_DIM: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write('# Phase 1: Matrix\\n')\n",
    "    file.write('# Features_1: 1\\n')\n",
    "    file.write('# Phase 2: Yarn\\n')\n",
    "    file.write(f'# Features_2: {yarns}\\n')  \n",
    "    file.write('#\\n')\n",
    "    file.write('# phi1 PHI phi2 x y z FeatureId PhaseId Symmetry')\n",
    "    file.write('\\n')\n",
    "    \n",
    "twoDebsddf.to_csv(OutputFileNameBase+\"2D_ebsd.txt\", mode='a', sep =' ', index=False, header=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates an EBSD file used for the BoxTest example. This example can be used for quick testing on a much smaller scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "with open(OutputFileNameBase+\"2D_ebsd.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    data_lines = lines[21:]\n",
    "    df_2d = pd.read_csv(io.StringIO(''.join(data_lines)), sep=' ', header=0)\n",
    "    df_2d.columns = df_2d.columns[1:].tolist() + [df_2d.columns[0]]\n",
    "    df_2d = df_2d.drop(columns=df_2d.columns[-1])\n",
    "    file.close()\n",
    "    # lines = file.readlines()\n",
    "    # print(lines[21:23])  # Print the first 10 lines to verify the content\n",
    "print(df_2d.head())  # Display the first few rows of the DataFrame to verify the content\n",
    "print(\"Number of rows in df_2d:\", len(df_2d))\n",
    "df_2d = df_2d[df_2d['x'] <= 12000]\n",
    "print(df_2d.head())\n",
    "print(\"Number of rows in df_2d:\", len(df_2d))\n",
    "df_2d = df_2d[df_2d['y'] >= 100000]\n",
    "print(df_2d.head())\n",
    "print(\"Number of rows in df_2d:\", len(df_2d))\n",
    "print(\"Unique values in x:\", df_2d['x'].nunique())\n",
    "print(\"Unique values in z:\", df_2d['y'].nunique())\n",
    "\n",
    "\n",
    "with open(\"SimpleBoxTest_EBSD.txt\", \"w\") as file:\n",
    "    file.write(f'# X_STEP: {x_step* NonDimConv}\\n')\n",
    "    file.write(f'# Y_STEP: {z_step* NonDimConv}\\n')\n",
    "    file.write(f'# Z_STEP: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MIN: {x_min}\\n')\n",
    "    file.write(f'# Y_MIN: 100000\\n')\n",
    "    file.write(f'# Z_MIN: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MAX: {x_max* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MAX: {z_max* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MAX: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_DIM: {df_2d[\"x\"].nunique()}\\n')\n",
    "    file.write(f'# Y_DIM: {df_2d[\"y\"].nunique()}\\n')\n",
    "    file.write(f'# Z_DIM: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write('# Phase 1: Matrix\\n')\n",
    "    file.write('# Features_1: 1\\n')\n",
    "    file.write('# Phase 2: Yarn\\n')\n",
    "    file.write(f'# Features_2: 2\\n')  \n",
    "    file.write('#\\n')\n",
    "    file.write('# phi1 PHI phi2 x y z FeatureId PhaseId Symmetry')\n",
    "    file.write('\\n')\n",
    "    \n",
    "df_2d.to_csv('SimpleBoxTest_EBSD.txt', mode='a', sep =' ', index=False, header=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic 3D EBSD File Generation\n",
    "\n",
    "Since TexGen always outputs a 3D file, we need to run this before creating any of the other file types. This will create our general 3D EBSD file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This entire script creates multiple different EBSD files that we can bring into Macaw. Since we will be doing edits to each to get them into the desired format for Macaw, I make a copy from our master box dataframe before going into each. There will be similar code in each file generation section, but it's typically on different data or in a different order to get the EBSD file that we want to load into Macaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebsddf = allpointsdf.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macaw has a different scale factor relative to the TexGen file. This adjusts the scale factor to be inline for Macaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebsddf[0] = ebsddf[0] * NonDimConv\n",
    "ebsddf[1] = ebsddf[1] * NonDimConv\n",
    "ebsddf[2] = ebsddf[2] * NonDimConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This checks if a fiber is defined for each point in our box so that it can define a different phase for fibers vs matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebsddf['phase'] = ebsddf['inHull'].mask(ebsddf['inHull'] >0, 2)\n",
    "ebsddf['phase'] = ebsddf['phase'].mask(ebsddf['phase'] <1, 1)\n",
    "ebsddf.insert(0, \"phi1\", 0)\n",
    "ebsddf.insert(1, \"phi2\", 0)\n",
    "ebsddf.insert(2, \"phi3\", 0)\n",
    "ebsddf.insert(8, \"symmetry\", 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the EBSD text file that we will import into Macaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OutputFileNameBase+\"3D_ebsd.txt\", \"w\") as file:\n",
    "    file.write(f'# X_STEP: {x_step* NonDimConv}\\n')\n",
    "    file.write(f'# Y_STEP: {y_step* NonDimConv}\\n')\n",
    "    file.write(f'# Z_STEP: {z_step* NonDimConv}\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MIN: {x_min* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MIN: {y_min* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MIN: {z_min* NonDimConv}\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MAX: {x_max* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MAX: {y_max* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MAX: {z_max* NonDimConv}\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_DIM: {x_dim}\\n')\n",
    "    file.write(f'# Y_DIM: {y_dim}\\n')\n",
    "    file.write(f'# Z_DIM: {z_dim}\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write('# Phase 1: Matrix\\n')\n",
    "    file.write('# Features_1: 1\\n')\n",
    "    file.write('# Phase 2: Yarn\\n')\n",
    "    file.write(f'# Features_2: {yarns}\\n')  \n",
    "    file.write('#\\n')\n",
    "    file.write('# phi1 PHI phi2 x y z FeatureId PhaseId Symmetry')\n",
    "    file.write('\\n')\n",
    "    \n",
    "ebsddf.to_csv(OutputFileNameBase+\"3D_ebsd.txt\", mode='a', sep =' ', index=False, header=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP 3D EBSD File with Voids\n",
    "This section produces an EBSD file for a 3D system and implements some basic voids to the system as well. Using this is not yet implemented in Macaw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before. We create a copy of our dataframe and then define our phase based on if there is an assigned fiber or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Voidsdf = allpointsdf.copy(deep=True)\n",
    "Voidsdf['phase'] = Voidsdf['inHull'].mask(Voidsdf['inHull'] >0, 2)\n",
    "Voidsdf['phase'] = Voidsdf['phase'].mask(Voidsdf['phase'] <1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create 50 voids with a radius of 0.1 around a center point chosen at random in our box. Each point in the void is checked against the phase to determine if that point is already defined as part of a fiber. If it is part of a fiber, that point in the void is ignored so we only overwrite points in our box that are defined as matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void_radius = .1\n",
    "\n",
    "for voidNum in range(50):\n",
    "    void = np.random.rand(3)\n",
    "\n",
    "    void[0] = void[0]*x_step*x_dim + x_min\n",
    "    void[1] = void[1]*y_step*y_dim + y_min\n",
    "    void[2] = void[2]*z_step*z_dim + z_min\n",
    "\n",
    "    Voidsdf['phase'] = Voidsdf['phase'].mask( (((abs(Voidsdf[0]-void[0]) + abs(Voidsdf[1]-void[1]) + abs(Voidsdf[2]-void[2])) < void_radius) &  (Voidsdf['phase']==1)), 3)\n",
    "\n",
    "Voidsdf['inHull'] = Voidsdf['inHull'].mask(Voidsdf['phase'] >2, yarns+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick visualization of our voids. As a note, the voids may look non-spherical due to the scale bars set automatically by the graph. The matrix isn't shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dryfiberdfvoid = Voidsdf.copy(deep=True)\n",
    "dryfiberdfvoid = dryfiberdfvoid[dryfiberdfvoid.inHull >0 ]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "x = dryfiberdfvoid.iloc[:,0]\n",
    "y = dryfiberdfvoid.iloc[:,1]\n",
    "z = dryfiberdfvoid.iloc[:,2]\n",
    "\n",
    "ax.scatter(x, y, z, c=dryfiberdfvoid.loc[:,\"inHull\"], cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next three sections add columns, adjust the scale to fit Macaw, and write the EBSD file that we'll import into Macaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Voidsdf.insert(0, \"phi1\", 0)\n",
    "Voidsdf.insert(1, \"phi2\", 0)\n",
    "Voidsdf.insert(2, \"phi3\", 0)\n",
    "Voidsdf.insert(8, \"symmetry\", 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Voidsdf[0] = Voidsdf[0] * NonDimConv\n",
    "Voidsdf[1] = Voidsdf[1] * NonDimConv\n",
    "Voidsdf[2] = Voidsdf[2] * NonDimConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OutputFileNameBase+\"withVoids_ebsd.txt\", \"w\") as file:\n",
    "    file.write(f'# X_STEP: {x_step* NonDimConv}\\n')\n",
    "    file.write(f'# Y_STEP: {y_step* NonDimConv}\\n')\n",
    "    file.write(f'# Z_STEP: {z_step* NonDimConv}\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MIN: {x_min* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MIN: {y_min* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MIN: {z_min* NonDimConv}\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MAX: {x_max* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MAX: {y_max* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MAX: {z_max* NonDimConv}\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_DIM: {x_dim}\\n')\n",
    "    file.write(f'# Y_DIM: {y_dim}\\n')\n",
    "    file.write(f'# Z_DIM: {z_dim}\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write('# Phase 1: Matrix\\n')\n",
    "    file.write('# Features_1: 1\\n')\n",
    "    file.write('# Phase 2: Yarn\\n')\n",
    "    file.write(f'# Features_2: {yarns}\\n')\n",
    "    file.write('# Phase 3: Voids\\n')\n",
    "    file.write('# Features_2: 1\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write('# phi1 PHI phi2 x y z FeatureId PhaseId Symmetry')\n",
    "    file.write('\\n')\n",
    "    \n",
    "Voidsdf.to_csv(OutputFileNameBase+\"withVoids_ebsd.txt\", mode='a', sep =' ', index=False, header=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP 2D EBSD file with Voids\n",
    "This section produces an EBSD file for a 2D system and implements some basic voids to the system as well. Using this is not yet implemented in Macaw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our new dataframe copy and define our phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDebsddfwithVoids = allpointsdf.copy(deep=True)\n",
    "twoDebsddfwithVoids['phase'] = twoDebsddfwithVoids['inHull'].mask(twoDebsddfwithVoids['inHull'] >0, 2)\n",
    "twoDebsddfwithVoids['phase'] = twoDebsddfwithVoids['phase'].mask(twoDebsddfwithVoids['phase'] <1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates voids similar to our 3D model, but doesn't check for the Y coordinate when defining the void. This means that it will create the void across the entire Y direction as long as it's within the radius in the XZ directions and not already defined as fiber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void_radius = .05\n",
    "\n",
    "for voidNum in range(50):\n",
    "    void = np.random.rand(3)\n",
    "\n",
    "    void[0] = void[0]*x_step*x_dim + x_min\n",
    "    void[1] = void[1]*y_step*y_dim + y_min\n",
    "    void[2] = void[2]*z_step*z_dim + z_min\n",
    "\n",
    "    twoDebsddfwithVoids['phase'] = twoDebsddfwithVoids['phase'].mask( (((abs(twoDebsddfwithVoids[0]-void[0]) + abs(twoDebsddfwithVoids[2]-void[2])) < void_radius) &  (twoDebsddfwithVoids['phase']==1)), 3)\n",
    "\n",
    "twoDebsddfwithVoids['inHull'] = twoDebsddfwithVoids['inHull'].mask(twoDebsddfwithVoids['phase'] >2, yarns+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the 2D slice from our 3D box, again from the middle of our Y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDebsddfwithVoids = twoDebsddfwithVoids[twoDebsddfwithVoids[1] == pd.to_numeric(\"{:.5f}\".format(y_start_value+(y_dim/2-1)*y_step))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph showing our 2D slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "x = twoDebsddfwithVoids.iloc[:,0]\n",
    "y = twoDebsddfwithVoids.iloc[:,1]\n",
    "z = twoDebsddfwithVoids.iloc[:,2]\n",
    "\n",
    "ax.scatter(x, y, z, c=twoDebsddfwithVoids.loc[:,\"inHull\"], alpha=0.1, cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next 3 sections change the scaling, flip to an XY system, add columns, and export our EBSD file that we can import into Macaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDebsddfwithVoids[0] = twoDebsddfwithVoids[0] * NonDimConv\n",
    "twoDebsddfwithVoids[1] = twoDebsddfwithVoids[1] * NonDimConv\n",
    "twoDebsddfwithVoids[2] = twoDebsddfwithVoids[2] * NonDimConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoDebsddfwithVoids= twoDebsddfwithVoids.drop(columns=[1])\n",
    "twoDebsddfwithVoids = twoDebsddfwithVoids.rename(columns={0: \"x\", 2: \"y\"})\n",
    "twoDebsddfwithVoids.insert(2, \"z\", 0)\n",
    "twoDebsddfwithVoids.insert(0, \"phi1\", 0)\n",
    "twoDebsddfwithVoids.insert(1, \"phi2\", 0)\n",
    "twoDebsddfwithVoids.insert(2, \"phi3\", 0)\n",
    "twoDebsddfwithVoids.insert(8, \"symmetry\", 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OutputFileNameBase+\"CharOx_2D_ebsd.txt\", \"w\") as file:\n",
    "    file.write(f'# X_STEP: {x_step* NonDimConv}\\n')\n",
    "    file.write(f'# Y_STEP: {z_step* NonDimConv}\\n')\n",
    "    file.write(f'# Z_STEP: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MIN: {x_min* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MIN: {z_min* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MIN: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_MAX: {x_max* NonDimConv}\\n')\n",
    "    file.write(f'# Y_MAX: {z_max* NonDimConv}\\n')\n",
    "    file.write(f'# Z_MAX: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write(f'# X_DIM: {x_dim}\\n')\n",
    "    file.write(f'# Y_DIM: {z_dim}\\n')\n",
    "    file.write(f'# Z_DIM: 0\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write('# Phase 1: Matrix\\n')\n",
    "    file.write('# Features_1: 1\\n')\n",
    "    file.write('# Phase 2: Yarn\\n')\n",
    "    file.write(f'# Features_2: {yarns}\\n')\n",
    "    file.write('# Phase 3: Voids\\n')\n",
    "    file.write('# Features_2: 1\\n')\n",
    "    file.write('#\\n')\n",
    "    file.write('# phi1 PHI phi2 x y z FeatureId PhaseId Symmetry')\n",
    "    file.write('\\n')\n",
    "    \n",
    "twoDebsddfwithVoids.to_csv(OutputFileNameBase+\"CharOx_2D_ebsd.txt\", mode='a', sep =' ', index=False, header=False, float_format='%.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
